require(caret)
require(doParallel)

## Load Data
setwd("~/Github/meta-learning/Meter A")
load("data_split.rda")

## Creat data meter a

y_train = as.factor(df_metera$y_train)
y_test = as.factor(df_metera$y_test)

x_train = df_metera$x_train
x_test = df_metera$x_test

x_train <- as.matrix(model.matrix( ~.^2, data=df_metera$x_train))
x_train <- x_train[,-1]
x_test = as.matrix(model.matrix( ~.^2, data=df_metera$x_test))
x_test <- x_test[,-1]

## Meta parameters
q0 <- .05 # quantile for screening
dmax <- 6 # max model size (Sam stops at models with 10 predictors)
mod_max <- 4e4 # model explored at each step


# data storage
CVs <- vector("list",dmax)
IDs <- vector("list",dmax)
VarMat <- vector("list",dmax)
set.seed(163L)
graine <- sample.int(1e6,dmax)

##


# Initial step: (dimension 1)
# EXAMPLE FOR D=1
cv_errors <- vector("numeric",ncol(x_train))
nc = detectCores()
cl <- makeCluster(cl)
registerDoParallel(cl)

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 1) #10 fold CV repeated 10 times as PANNING

cv_errors <- foreach(i = seq_along(cv_errors), .combine = c, .packages=c("caret")) %dopar% {
  seed <- graine[1] + i
  X <- as.matrix(x_train[,i])
  y <- as.factor(y_train)
  breast_1 = data.frame(y,X)
  obj = train(y ~., data = breast_1, method = "svmLinear", trControl=trctrl, preProcess = c("center", "scale"),tuneLength = 10)
  cv_errors = 1 - max(obj$results$Accuracy)
}
stopCluster(cl)

CVs[[1]] <- cv_errors
VarMat[[1]] <- seq_along(cv_errors)

cv_errors <- cv_errors[!is.na(cv_errors)]

IDs[[1]] <- which(cv_errors <= quantile(cv_errors,q0))

save(CVs,file="CVs_svml_metera.rda")
save(IDs,file="IDs_svml_metera.rda")
save(VarMat,file="VarMat_svml_metera.rda") #each row of VarMat gives me the tested regressors (at most 40000)
id_screening <- IDs[[1]]


# Dimension d >= 2

for(d in 2:dmax){
  
  # cv0 <- cv1
  idRow <- IDs[[d-1]]
  if(d==2){
    idVar <- VarMat[[d-1]][idRow]
    nrv <- length(idVar)
  }else{
    idVar <- VarMat[[d-1]][idRow,]
    nrv <- nrow(idVar)
  }
  # build all possible 
  A <- matrix(nr=nrv*length(id_screening),nc=d)
  A[,1:(d-1)] <- kronecker(cbind(rep(1,length(id_screening))),idVar)
  A[,d] <- rep(id_screening,each=nrv)
  B <- unique(t(apply(A,1,sort)))
  id_ndup <- which(apply(B,1,anyDuplicated) == 0)
  var_mat <- B[id_ndup,]
  rm(list=c("A","B"))
  
  if(nrow(var_mat)>mod_max){
    set.seed(graine[d]+1)
    VarMat[[d]] <- var_mat[sample.int(nrow(var_mat),mod_max),]
  }else{
    VarMat[[d]] <- var_mat
  }
  
  var_mat <- VarMat[[d]]
  
  cv_errors <- rep(NA,nrow(var_mat))
  nc = detectCores()
  cl <- makeCluster(nc)
  registerDoParallel(cl)
  
  trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 1) #10 fold CV repeated 10 times as PANNING

  cv_errors <- foreach(i = seq_along(cv_errors), .combine = c, .packages=c("caret")) %dopar% {
    rc <- var_mat[i,]
    seed <- graine[1] + i
    X <- as.matrix(x_train[,rc])
    y <- as.factor(y_train)
    breast_1 = data.frame(y,X)
    obj = train(y ~., data = breast_1, method = "svmLinear", trControl=trctrl, preProcess = c("center", "scale"),tuneLength = 10)
    cv_errors = 1 - max(obj$results$Accuracy)
  }
  stopCluster(cl)
  
  
  attr(cv_errors,"rng") <- NULL
  
  CVs[[d]] <- cv_errors
  cv1 <- quantile(cv_errors,probs=q0,na.rm=T)
  IDs[[d]] <- which(cv_errors<=cv1)
  
  save(CVs,file="CVs_svml_metera.rda")
  save(IDs,file="IDs_svml_metera.rda")
  save(VarMat,file="VarMat_svml_metera.rda")
  print(d)
}


m_vector <- sapply(CVs[c(1:dmax)], function(x) summary(x)[4])
l_vector <- sapply(CVs[c(1:dmax)], function(x) summary(x)[1])
u_vector <- sapply(CVs[c(1:dmax)], function(x) summary(x)[6])
require(plotrix)


## 1152 model below 1%

plotCI(1:dmax, m_vector, ui=u_vector, li=l_vector, scol = "grey", col="red"
       , pch = 16, main = "Set of Highly Predictive Models - III Cartesian Quadrant",ylab = "Range CV Error",xlab = "Model Size")
mod_size_min = which.min(unlist(lapply(CVs[1:dmax], min)))
abline(v = mod_size_min, col="blue",lwd=2)
ab = quantile(CVs[[mod_size_min]],seq(0, 1, 0.01))[2]
abline(h = ab, col="blue",lwd=2)

setwd("~/GitHub/meta-learning/Meter A")

load("CVs_svml_metera.rda")
load("IDs_svml_metera.rda")
load("VarMat_svml_metera.rda")

# Cross validation graph

# Vector of dimention of the model selected 
dim_model = 2:6

# Find the index of model selected
index_model_select = list()
for(i in seq_along(dim_model)){
  index_model_select[[i]] = which(((CVs[[dim_model[i]]] <=ab)))
}

# length of model selected
n_models_selected = length(unlist(index_model_select))


## function to get the selected covariate name, frequency and position in the X matrix

list_covariate_selected = function(VarMat,dim_model,index_model_select){
  var_mat_select_list = list()
  for(d in seq_along(dim_model)){
    var_mat_select_list[[d]] <- VarMat[[dim_model[d]]][index_model_select[[d]],]
  }
  table_variable = table(unlist(var_mat_select_list))
  gene_index = as.numeric(rownames(table_variable))
  out = structure(list(model_select = var_mat_select_list,
                       table = table_variable,
                       gene_index = gene_index))
  invisible(out)
}

cov_breast = list_covariate_selected(VarMat,dim_model,index_model_select)

svm_evalutation = function(dim_model,cov_breast,x_train,x_test,y_train,y_test){
  # Counting error list
  ce = list()
  # y for training sample
  ytr <- as.factor(y_train)
  yte <- as.factor(y_test)
  # Options for svm function
  trctrl <- trainControl(method = "cv", number = 10) #10 fold CV
  test_pred_list = list()
  for(d in seq_along(dim_model)){
    # Matrix of selected variables at dimention d
    var_mat_select <- cov_breast$model_select[[d]]
    # Initialize vector of counting errors
    if(is.null(dim(cov_breast$model_select[[d]])) ){
      counting_error_svm = rep(NA,1)
      test_pred = matrix(NA,length(y_test),1)
      pb1 = 1
      n_mod_dim = 1
    }else{
      counting_error_svm = rep(NA,dim(var_mat_select)[1])
      test_pred = matrix(NA,length(y_test),dim(var_mat_select)[1])
      pb1 = dim(var_mat_select)[1]
      n_mod_dim = dim(var_mat_select)[1]
    }
    # Store the vector of prediction
    nc = detectCores()
    cl <- makeCluster(nc)
    registerDoParallel(cl)
    
    pb <- txtProgressBar(min = 0, max = pb1, style = 3)
    for(j in 1:n_mod_dim){
      # Index of selected covariate of model j
      
      rc <- var_mat_select[j,]
      # New X train matrix and create data frame for svm computation
      X1 <- as.matrix(x_train[,rc])
      breast_1 = data.frame(ytr,X1)
      # Svm object 
      svm_radial = caret::train(ytr ~., data = breast_1, method = "svmLinear", 
                                trControl=trctrl, preProcess = c("center", "scale"),tuneLength = 10)
      ## Counting errors and confusion matrix
      # X test matrix and create data frame for svm computation
      X2 = x_test[,rc]
      df1 <- data.frame(yte, X2)
      # create the data matrix for prediction storage
      df2 <- data.frame(X2)
      # make precition out-of-sample
      test_pred[,j] <- predict(svm_radial, newdata = df2)
      # Store confusion matrix
      obj2 = confusionMatrix(table(predict(svm_radial, newdata = df2), df1$yte))
      # Compute the counting error
      counting_error_svm[j] = sum(as.vector(obj2$table)[c(2,3)])
      setTxtProgressBar(pb, j)
    }
    stopCluster(cl)
    ## Sort the signs and extract the quantile when it changes
    # List of counting error for various model dimention
    ce[[d]] = counting_error_svm
    # List of matrices of prediction
    test_pred_list[[d]] =  test_pred
    print(d)
  }
  
  count_error = unlist(ce)
  # Majority rule svm
  mat_test_pred = do.call(cbind,test_pred_list)
  #mat_test_pred[mat_test_pred == 1] = 0
  #mat_test_pred[mat_test_pred == 2] = 1
  pred_mod_av = (round(apply(mat_test_pred,1,mean)))
  # counting error model averaging
  mode_av_ce = abs(sum(pred_mod_av-as.numeric(y_test)))
  out = structure(list(ma_ce = mode_av_ce,
                       mat_test_pred = mat_test_pred,
                       ce_all = count_error))
  invisible(out)
}

test_svml_metera = svm_evalutation(dim_model,cov_breast,x_train,x_test,y_train,y_test)

save(test_svml_metera,file = "test_svml_metera.rda")

# Store the vector of prediction
nc = detectCores()
cl <- makeCluster(nc)
registerDoParallel(cl)

# New X train matrix and create data frame for svm computation
X1 <- as.matrix(x_train)
breast_1 = data.frame(ytr,X1)
# Svm object 
svm_radial = caret::train(ytr ~., data = breast_1, method = "svmLinear", 
                          trControl=trctrl, preProcess = c("center", "scale"),tuneLength = 10)
## Counting errors and confusion matrix
# X test matrix and create data frame for svm computation
X2 = x_test
df1 <- data.frame(yte, X2)
# create the data matrix for prediction storage
df2 <- data.frame(X2)
# make precition out-of-sample
test_pred_full <- predict(svm_radial, newdata = df2)
# Store confusion matrix
obj2 = confusionMatrix(table(predict(svm_radial, newdata = df2), df1$yte))
# Compute the counting error
counting_error_svm_full = sum(as.vector(obj2$table)[c(2,3)])


barplot(table(test_svml_metera$ce_all), main = "Counting Error Panning algo with SVM linear",ylab = "Number of Models",xlab = "Counting Error Measure",
        ylim = range(0,400))# Lasso is at 4 errors but with models with at least 13 up to 39 regressors while PANNING does this with less than 8 regressors
abline(v = 0.7, col="red",lwd=2)

legend("topright", legend=c("Panning MA"),
       col=c("red", "green", "blue"), lty=1, cex=0.8, box.lty=0)
